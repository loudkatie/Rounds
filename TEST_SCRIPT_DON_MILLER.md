# ðŸŽ¤ DON MILLER ICU ROUNDS SCRIPT
## Read this aloud to test Rounds AI

---

**Setting:** UF Health Gainesville, Pulmonary ICU, Morning Rounds
**Patient:** Don Miller, 75-year-old male, POD 6 bilateral lung transplant

---

### DR. MARTINEZ (Attending):

"Good morning team. Let's round on Mr. Miller in bed 4. Don Miller, 75-year-old male, post-op day 6 from bilateral sequential lung transplant for end-stage IPF. 

Overnight he remained hemodynamically stable on room air, which is excellent progress. His tacrolimus trough this morning came back at 9.8, which is within our therapeutic window of 8 to 12. We'll keep his current dose at 3 milligrams twice daily.

His creatinine bumped slightly to 1.6 from 1.4 yesterday. I'm not overly concerned yet but let's hold his vancomycin and trend the BMP. Could be early tacrolimus nephrotoxicity or just volume status.

Bronchoscopy yesterday showed A0 B0 on transbronchial biopsies - that means no acute cellular rejection, which is the news we wanted. BAL cultures are pending but gram stain was negative.

His chest x-ray this morning shows expected post-surgical changes with small bilateral pleural effusions, stable from yesterday. We'll continue incentive spirometry and chest PT.

Pain is well controlled on his current PCA settings. He's using about 15 milligrams of morphine equivalent over 24 hours.

Plan: Continue triple immunosuppression with tacrolimus, mycophenolate, and prednisone. Start prednisone taper tomorrow, down to 20 milligrams daily. Check tacrolimus trough again in 48 hours. If creatinine continues trending up, we'll need nephrology consult.

PT cleared him for ambulation today so let's get him up and walking. Goal is 3 laps around the unit. If he tolerates that well and his labs look good tomorrow, we can start talking about transfer to the step-down unit maybe Thursday or Friday.

Any questions from the team? No? Alright, let's move to bed 5."

---

**Key medical terms the AI should translate:**
- POD 6 = Post-operative day 6
- Hemodynamically stable = Heart and blood pressure are steady
- Tacrolimus trough = Blood level of anti-rejection medication
- Creatinine = Kidney function marker
- BMP = Basic metabolic panel (blood test)
- A0 B0 = No rejection on biopsy scale
- BAL = Bronchoalveolar lavage (lung wash sample)
- Triple immunosuppression = Three anti-rejection medications
- PCA = Patient-controlled pain pump
- PT = Physical therapy

MORE BACKGROUND on LOUD LABS and our Proactive Hosted AI Companions  model: 
# LOUD LABS: Product Framework v2.0

**Created:** January 29, 2026  
**Authors:** Katie (CEO) + Claude (CTO)  
**Status:** Living Document â€” The Bible for All Loud Labs Development

---

## Executive Summary

Loud Labs builds **Proactive Hosted AI Companions** â€” software that feels like a relationship, not a tool.

We are not building chatbots. We are not building assistants. We are building AI that:
- **Initiates** (never waits for the user to figure out what to do)
- **Remembers** (every session deepens a continuous relationship)
- **Observes** (learns from behavior, not just words)
- **Grows** (the profile is never complete â€” it deepens over months)

Our target users are **non-tech Americans** â€” Gen X and Boomers who are iPhone-capable but have never used AI. This will be their first AI experience, and it should feel like texting a knowledgeable friend.

---

## Table of Contents

1. [The Philosophy](#the-philosophy)
2. [The Five Pillars](#the-five-pillars)
3. [The Adaptive Context Engine](#the-adaptive-context-engine)
4. [Technical Architecture](#technical-architecture)
5. [Rounds V1 â†’ V2 Evolution](#rounds-v1--v2-evolution)
6. [Implementation Guidelines](#implementation-guidelines)
7. [Design System](#design-system)
8. [What's Next](#whats-next)

---

## The Philosophy

### The Core Insight

> "We observe what humans DO, not just what they SAY."

Every AI product today treats the transcript as the data. User says something â†’ AI responds. But the **real** data is behavioral:

- **When** do they open the app? (Anxious at 2am? Routine at breakfast?)
- **How long** do they engage? (Getting shorter? Longer?)
- **What don't they say?** (Avoiding topics they used to mention?)
- **How do they respond?** (Engaged? Dismissive? Deflecting?)
- **What patterns emerge** over weeks, not sessions?

Humans learn each other this way. You know your friend is stressed not because she said "I'm stressed" but because she's been short in texts, canceled plans, and ordered wine at lunch on a Tuesday.

**We build AI that notices the wine at lunch.**

### The Relationship Model

Traditional apps have **sessions**. User opens app â†’ does thing â†’ closes app. Each session is independent.

Loud Labs apps have **relationships**. Every interaction is part of one continuous, deepening conversation. Session 47 knows everything from sessions 1-46. The AI remembers your father's name, your concerns, your patterns, your questions.

This is identical to how human trust works:
- **Week 1:** Polite, surface-level, learning basics
- **Month 1:** Familiar, remembers context, starts noticing patterns
- **Month 6:** Deep understanding, anticipates needs, feels like a friend

You can't rush this. Users can't skip to deep trust even if they want to. Trust builds through consistency and demonstrated understanding over time.

### The Proactive Principle

> "Never present a blank box."

The user should never have to figure out what to do next. The AI always knows the next move.

**Bad:** "How can I help you today?" (blank canvas â€” user has to think)
**Bad:** "How are you?" (conversational blank box â€” user has to generate content)
**Good:** "Last time we talked, you mentioned Don's creatinine was trending up. Did today's labs come back?"

A **guided question** demonstrates memory, gives the user something to respond to, and moves the relationship forward. This is what friends do. This is what good doctors do. This is what Loud Labs apps do.

### The Hosted Experience

The AI is the **host**. The user is the **guest**.

Think of the best restaurant you've ever been to. The host greets you, seats you, explains the specials, anticipates your needs, checks in at the right moments. You never have to flag someone down. You never feel lost.

That's every Loud Labs app. From the first tap, the AI is already talking. It guides. It suggests. It remembers. The user relaxes into being taken care of.

---

## The Five Pillars

Every Loud Labs app implements these five pillars:

### 1. Proactive AI

The AI initiates. Always.

- First open: AI greets, explains itself, asks the first question
- Return visits: AI picks up where you left off, references past context
- Between sessions: AI identifies gaps and strategically fills them
- Notifications: AI reaches out when it has something useful (not spam)

The user never sees a blank screen. The user never has to generate the first move.

### 2. Chat-First Interface

iMessage-style bubbles. Familiar to anyone who texts.

- No learning curve
- No forms to fill out
- No settings screens to navigate
- Just conversation

The AI feels like a contact in your phone, not an app you operate.

### 3. Persistent Memory

The AI remembers **everything**:

- Identity (names, relationships, context)
- History (every session, every detail mentioned)
- Patterns (behavioral trends across sessions)
- Preferences (how they like to communicate)

Day 1 and Day 100 feel like the same continuous relationship. The AI never asks for information it should already know.

### 4. Behavioral Learning

We learn from **what users do**, not just what they say:

- Session timing (when do they engage?)
- Session length (are they rushing or lingering?)
- Response patterns (engaged vs. dismissive)
- Topic avoidance (what did they stop mentioning?)
- Emotional signals (sentiment, vocabulary shifts)

This data informs insights the user couldn't generate themselves: "Your three best rounds were all on humid days â€” any idea why?"

### 5. Progressive Deepening

The profile is **never complete**. It deepens over weeks and months.

- **Session 1:** Name, basic context
- **Session 5:** Patterns emerging, relationship familiar
- **Session 20:** Deep understanding, anticipates needs
- **Session 50:** Knows user better than they know themselves

This cannot be rushed. Trust and understanding build through consistency over time.

---

## The Adaptive Context Engine

This is the technical innovation at the heart of Loud Labs v2.

### The Problem with V1

In Rounds V1, the AI stores what it learns from sessions â€” but it's **passive**. It waits for information to come to it. If the user doesn't mention something, the AI never knows.

### The V2 Solution

The Adaptive Context Engine **actively identifies what it doesn't know** and strategically fills those gaps through lightweight, gamified micro-interactions.

After every session, the AI runs a **gap analysis**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              POST-SESSION GAP ANALYSIS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  What do we KNOW with confidence?                           â”‚
â”‚  âœ“ Caregiver: Katie                                        â”‚
â”‚  âœ“ Patient: Don (father)                                   â”‚
â”‚  âœ“ Diagnosis: Double lung transplant                       â”‚
â”‚  âœ“ Surgery date: October 2025                              â”‚
â”‚  âœ“ Last 5 sessions: summaries captured                     â”‚
â”‚                                                             â”‚
â”‚  What's UNCLEAR or MISSING?                                 â”‚
â”‚  ? Care team members â€” only Dr. Chen mentioned             â”‚
â”‚  ? Current medications â€” partial list                      â”‚
â”‚  ? Home care situation â€” unclear                           â”‚
â”‚                                                             â”‚
â”‚  What's SHALLOW (mentioned but not explored)?              â”‚
â”‚  â–³ "The night nurse" â€” who is this?                        â”‚
â”‚  â–³ "His wife" â€” patient's spouse, no name                  â”‚
â”‚  â–³ Transportation to appointments â€” mentioned concern      â”‚
â”‚                                                             â”‚
â”‚  What would UNLOCK new insight categories?                  â”‚
â”‚  â˜… 3 more sessions = can detect day-of-week patterns      â”‚
â”‚  â˜… Medication list = can flag interactions                 â”‚
â”‚  â˜… Care team = can personalize doctor-specific advice      â”‚
â”‚                                                             â”‚
â”‚  PRIORITY QUEUE FOR NEXT CONTRIBUTION:                      â”‚
â”‚  1. [QUICK] "Is Don still at UF Gainesville?"              â”‚
â”‚  2. [CHOICE] "Who else is on the care team besides Chen?"  â”‚
â”‚  3. [SHORT] "You mentioned a night nurse â€” tell me more?"  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Contribution Framework

Users earn points by filling gaps. This is modeled on Google Maps Local Guides â€” proven psychology that works.

**Contribution Types (easiest â†’ hardest):**

| Type | Points | Example |
|------|--------|---------|
| Quick Confirm | 5 | "Is Don still at UF?" (yes/no) |
| Rapid Choice | 10 | "Which concerns you most?" (pick from 3) |
| Short Answer | 25 | "Who else is on the care team?" |
| Mini Session | 50 | "60 seconds: Walk me through a typical day" |
| Deep Context | 100 | "Tell me about the transplant journey from the beginning" |

**Levels:**

| Level | Points | Title | Unlock |
|-------|--------|-------|--------|
| 1 | 0 | New | Basic features |
| 2 | 100 | Regular | Pattern detection begins |
| 3 | 300 | Trusted | Proactive insights |
| 4 | 600 | Connected | Predictive alerts |
| 5 | 1000 | Partner | Deep behavioral analysis |

**The key insight:** Higher levels = better insights. Not because we're withholding value, but because **we literally can't give deep pattern analysis until we have enough data.**

"You've reached Level 3. I now have enough context to start spotting patterns. Here's what I'm seeing..."

This reframes data collection from "we want your data" to "you're earning better insights."

### The Question Vault

The AI draws from a **vault of potential questions**, prioritized dynamically based on:

- **Recency:** Missing data from recent session = urgent
- **Impact:** Filling this gap unlocks new insight categories
- **Confidence:** We have a guess but need confirmation
- **User readiness:** Don't ask deep questions until trust is built

**Question Categories:**

1. **Identity** â€” Asked once, updated rarely
   - Names, relationships, basic context

2. **Situational** â€” Asked periodically as situation evolves
   - Care team, medications, current concerns

3. **Session-Specific** â€” Asked after each session
   - How did it go? What happened? Anything new?

4. **Clarification** â€” Triggered by ambiguity
   - "You mentioned X â€” can you tell me more?"

5. **Pattern Exploration** â€” Triggered by detected patterns
   - "I've noticed Y happens when Z. Any idea why?"

6. **Contribution** â€” Crowdsourced knowledge (for community features)
   - "What would you tell another caregiver in this situation?"

---

## Technical Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LOUD LABS APP ARCHITECTURE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  TRIGGER LAYER                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Geofence   â”‚  â”‚  Calendar   â”‚  â”‚   Manual    â”‚         â”‚
â”‚  â”‚  (arrive/   â”‚  â”‚  (events    â”‚  â”‚   (user     â”‚         â”‚
â”‚  â”‚   leave)    â”‚  â”‚   detected) â”‚  â”‚   opens)    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                          â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚              PROACTIVE ENGINE                    â”‚       â”‚
â”‚  â”‚                                                  â”‚       â”‚
â”‚  â”‚  Decides: What should AI say/do right now?      â”‚       â”‚
â”‚  â”‚  Inputs: Trigger type, user context, gap queue  â”‚       â”‚
â”‚  â”‚  Output: Proactive message or guided flow       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                          â”‚                                  â”‚
â”‚                          â–¼                                  â”‚
â”‚  INTERFACE LAYER                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   iPhone    â”‚  â”‚Apple Watch  â”‚  â”‚  AirPods    â”‚         â”‚
â”‚  â”‚  Chat UI    â”‚  â”‚  Haptics    â”‚  â”‚  Voice Out  â”‚         â”‚
â”‚  â”‚  (primary)  â”‚  â”‚  Voice In   â”‚  â”‚  (optional) â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                          â”‚                                  â”‚
â”‚                          â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚           ADAPTIVE CONTEXT ENGINE                â”‚       â”‚
â”‚  â”‚                                                  â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚       â”‚
â”‚  â”‚  â”‚   Memory    â”‚  â”‚     Gap     â”‚              â”‚       â”‚
â”‚  â”‚  â”‚   Store     â”‚  â”‚   Analyzer  â”‚              â”‚       â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚              â”‚       â”‚
â”‚  â”‚  â”‚ - Identity  â”‚  â”‚ - What's    â”‚              â”‚       â”‚
â”‚  â”‚  â”‚ - History   â”‚  â”‚   missing?  â”‚              â”‚       â”‚
â”‚  â”‚  â”‚ - Patterns  â”‚  â”‚ - Priority  â”‚              â”‚       â”‚
â”‚  â”‚  â”‚ - Behavior  â”‚  â”‚   queue     â”‚              â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚       â”‚
â”‚  â”‚                                                  â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚       â”‚
â”‚  â”‚  â”‚  Learning   â”‚  â”‚   Progress  â”‚              â”‚       â”‚
â”‚  â”‚  â”‚    Loop     â”‚  â”‚   Tracker   â”‚              â”‚       â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚              â”‚       â”‚
â”‚  â”‚  â”‚ - Extract   â”‚  â”‚ - Points    â”‚              â”‚       â”‚
â”‚  â”‚  â”‚   facts     â”‚  â”‚ - Levels    â”‚              â”‚       â”‚
â”‚  â”‚  â”‚ - Detect    â”‚  â”‚ - Unlocks   â”‚              â”‚       â”‚
â”‚  â”‚  â”‚   patterns  â”‚  â”‚             â”‚              â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                          â”‚                                  â”‚
â”‚                          â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                 AI LAYER (GPT-4)                 â”‚       â”‚
â”‚  â”‚                                                  â”‚       â”‚
â”‚  â”‚  System prompt includes:                        â”‚       â”‚
â”‚  â”‚  - Full memory context                          â”‚       â”‚
â”‚  â”‚  - Current gap priorities                       â”‚       â”‚
â”‚  â”‚  - Behavioral observations                      â”‚       â”‚
â”‚  â”‚  - App-specific personality                     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Architecture (V2)

```swift
struct AdaptiveMemoryContext: Codable {
    
    // MARK: - Core Identity (V1)
    var userName: String
    var userContext: [String: String]  // Flexible key-value for app-specific identity
    
    // MARK: - Learned Knowledge (V1, enhanced)
    var knownFacts: [KnownFact]  // Facts with confidence scores
    var observedPatterns: [ObservedPattern]  // Patterns with evidence
    var sessionHistory: [SessionSummary]
    
    // MARK: - Behavioral Data (V2 NEW)
    var behavioralSignals: BehavioralProfile
    
    // MARK: - Gap Analysis (V2 NEW)
    var knowledgeGaps: [KnowledgeGap]
    var priorityQueue: [PrioritizedQuestion]
    
    // MARK: - Progress Tracking (V2 NEW)
    var contributionPoints: Int
    var currentLevel: Int
    var unlockedFeatures: [String]
}

struct KnownFact: Codable {
    let id: UUID
    let category: String  // "identity", "medical", "preference", etc.
    let content: String
    let confidence: Double  // 0.0 - 1.0
    let source: String  // "user_stated", "ai_inferred", "confirmed"
    let learnedDate: Date
    let lastConfirmed: Date?
}

struct ObservedPattern: Codable {
    let id: UUID
    let description: String
    let evidence: [String]  // Session IDs or observations that support this
    let confidence: Double
    let firstObserved: Date
    let occurrences: Int
}

struct BehavioralProfile: Codable {
    var sessionTimings: [Date]  // When do they use the app?
    var sessionDurations: [TimeInterval]  // How long?
    var responseLatencies: [TimeInterval]  // How quickly do they respond?
    var topicFrequencies: [String: Int]  // What do they talk about?
    var sentimentTrend: [Double]  // Emotional trajectory over time
    var engagementScore: Double  // Calculated metric
}

struct KnowledgeGap: Codable {
    let id: UUID
    let category: String
    let description: String
    let importance: Double  // How much would filling this improve insights?
    let suggestedQuestions: [String]
    let createdDate: Date
}

struct PrioritizedQuestion: Codable {
    let id: UUID
    let question: String
    let type: QuestionType  // quick_confirm, choice, short_answer, deep
    let targetGap: UUID?  // Which gap does this fill?
    let priority: Double  // Calculated based on recency, impact, readiness
    let points: Int
}

enum QuestionType: String, Codable {
    case quickConfirm = "quick_confirm"  // 5 points
    case rapidChoice = "rapid_choice"    // 10 points
    case shortAnswer = "short_answer"    // 25 points
    case miniSession = "mini_session"    // 50 points
    case deepContext = "deep_context"    // 100 points
}
```

### Gap Analysis Algorithm

```swift
class GapAnalyzer {
    
    func analyzeGaps(memory: AdaptiveMemoryContext) -> [KnowledgeGap] {
        var gaps: [KnowledgeGap] = []
        
        // 1. Check for stale or unconfirmed facts
        for fact in memory.knownFacts {
            if fact.confidence < 0.7 {
                gaps.append(createConfirmationGap(for: fact))
            }
            if let lastConfirmed = fact.lastConfirmed,
               daysSince(lastConfirmed) > 30 {
                gaps.append(createRefreshGap(for: fact))
            }
        }
        
        // 2. Check for shallow knowledge areas
        let categoryCounts = memory.knownFacts.grouped(by: \.category)
        for (category, facts) in categoryCounts {
            if facts.count < minimumForCategory(category) {
                gaps.append(createDepthGap(for: category))
            }
        }
        
        // 3. Check for pattern prerequisites
        if memory.sessionHistory.count >= 5 && memory.observedPatterns.isEmpty {
            gaps.append(createPatternExplorationGap())
        }
        
        // 4. App-specific gaps (override in subclass)
        gaps.append(contentsOf: appSpecificGaps(memory))
        
        return gaps.sorted { $0.importance > $1.importance }
    }
    
    func prioritizeQuestions(gaps: [KnowledgeGap], memory: AdaptiveMemoryContext) -> [PrioritizedQuestion] {
        var questions: [PrioritizedQuestion] = []
        
        for gap in gaps.prefix(10) {  // Top 10 gaps
            for suggestion in gap.suggestedQuestions {
                let priority = calculatePriority(
                    gap: gap,
                    memory: memory,
                    question: suggestion
                )
                questions.append(PrioritizedQuestion(
                    id: UUID(),
                    question: suggestion,
                    type: inferQuestionType(suggestion),
                    targetGap: gap.id,
                    priority: priority,
                    points: pointsForType(inferQuestionType(suggestion))
                ))
            }
        }
        
        return questions.sorted { $0.priority > $1.priority }
    }
    
    private func calculatePriority(gap: KnowledgeGap, memory: AdaptiveMemoryContext, question: String) -> Double {
        var score = gap.importance
        
        // Recency boost: gaps from recent sessions are more urgent
        let daysSinceCreated = daysSince(gap.createdDate)
        if daysSinceCreated < 7 {
            score *= 1.5
        }
        
        // Trust adjustment: don't ask deep questions too early
        if memory.currentLevel < 2 && inferQuestionType(question) == .deepContext {
            score *= 0.3
        }
        
        // Engagement adjustment: if user is highly engaged, can ask harder questions
        if memory.behavioralSignals.engagementScore > 0.8 {
            score *= 1.2
        }
        
        return score
    }
}
```

---

## Rounds V1 â†’ V2 Evolution

### What V1 Does Well

1. **Memory persistence** â€” AIMemoryContext stores identity, facts, vitals, patterns
2. **Learning loop** â€” OpenAIService extracts and saves new facts each session
3. **Guided onboarding** â€” 5-step conversational flow
4. **Session chaining** â€” Multiple recordings within 1 hour treated as one session
5. **Context injection** â€” Every API call includes full memory context

### What V2 Adds

| V1 | V2 |
|----|-----|
| Passive memory (stores what it hears) | Active memory (seeks to fill gaps) |
| Fixed onboarding (5 questions, done) | Progressive onboarding (never complete) |
| No behavioral tracking | Full behavioral profile |
| No gamification | Points, levels, unlocks |
| Generic follow-up questions | Prioritized gap-filling questions |
| Session-based thinking | Relationship-based thinking |

### V2 Implementation Plan for Rounds

**Phase 1: Behavioral Foundation**
- Add `BehavioralProfile` to memory
- Track session timing, duration, response patterns
- No UI changes â€” just start collecting data

**Phase 2: Gap Analysis**
- Implement `GapAnalyzer` for Rounds-specific gaps
- Add `KnowledgeGap` tracking to memory
- Generate prioritized question queue after each session

**Phase 3: Contribution UI**
- Add "Between Sessions" contribution flow
- Implement points and level system
- Show progress indicator in app

**Phase 4: Insight Unlocks**
- Level 2: Pattern detection ("I've noticed...")
- Level 3: Proactive alerts ("Don's creatinine trending up")
- Level 4: Predictive insights ("Based on patterns, watch for...")

### Rounds-Specific Gap Categories

| Category | Example Gaps | Why It Matters |
|----------|--------------|----------------|
| Care Team | "Who else besides Dr. Chen?" | Personalize advice per doctor |
| Medications | "Complete medication list?" | Flag interactions, track changes |
| Home Situation | "Who helps at home?" | Understand support system |
| Caregiver Wellness | "How are YOU holding up?" | Support the supporter |
| Historical Context | "Walk me through the journey" | Deeper understanding |
| Logistics | "How do you get to appointments?" | Anticipate challenges |

---

## Implementation Guidelines

### Rules for Engineering

1. **Never present a blank box.** Every screen has AI-initiated content.

2. **Sessions are not sessions.** They're chapters in one continuous story. Always reference past context.

3. **Behavior over words.** Track what users do, not just what they say.

4. **The profile is never complete.** Always have questions queued.

5. **Gamification serves insight.** Points and levels exist to get better data, not to be a game.

6. **Trust builds slowly.** Don't ask deep questions until Level 2+.

7. **Memory is sacred.** Never lose data. Never ask for something we should know.

8. **Proactive, not pushy.** Reach out when useful. Don't spam.

### Code Standards

- **Platform:** iOS 17+, Swift 5.9, SwiftUI
- **AI:** OpenAI GPT-4o-mini (cost-efficient)
- **Storage:** Local first (UserDefaults/JSON), cloud sync later
- **Architecture:** MVVM with service layer
- **Testing:** Unit tests for gap analysis, integration tests for learning loop

### File Organization

```
{AppName}/
â”œâ”€â”€ App/
â”‚   â””â”€â”€ {AppName}App.swift
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ AdaptiveMemoryContext.swift  // V2 memory
â”‚   â”œâ”€â”€ BehavioralProfile.swift
â”‚   â”œâ”€â”€ KnowledgeGap.swift
â”‚   â””â”€â”€ {AppSpecific}Models.swift
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ MemoryStore.swift
â”‚   â”œâ”€â”€ GapAnalyzer.swift
â”‚   â”œâ”€â”€ OpenAIService.swift
â”‚   â”œâ”€â”€ BehavioralTracker.swift
â”‚   â””â”€â”€ ProgressTracker.swift
â”œâ”€â”€ ViewModels/
â”‚   â””â”€â”€ {Feature}ViewModel.swift
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ Onboarding/
â”‚   â”œâ”€â”€ Main/
â”‚   â”œâ”€â”€ Contribution/  // V2 between-session UI
â”‚   â””â”€â”€ Progress/      // V2 levels and unlocks
â””â”€â”€ Resources/
    â””â”€â”€ QuestionVault.json  // App-specific question bank
```

---

## Design System

### Core Principles

1. **Familiar.** iMessage bubbles. No learning curve.
2. **Warm.** Friendly, never clinical. Like texting a friend.
3. **Minimal.** Maximum 2 actions per screen. No clutter.
4. **Fast.** Real-time streaming. No spinners.
5. **Accessible.** Large text, high contrast, voice-first option.

### Color Palette (Rounds)

```swift
struct AppColor {
    static let primary = Color(red: 56/255, green: 152/255, blue: 224/255)  // Calm blue
    static let background = Color.white
    static let surface = primary.opacity(0.08)
    static let textPrimary = Color(red: 40/255, green: 40/255, blue: 50/255)
    static let textSecondary = Color(red: 80/255, green: 80/255, blue: 90/255)
    static let textMuted = Color.gray
    static let success = Color.green
    static let warning = Color.orange
    static let error = Color.red
}
```

### Progress Visualization

Users are motivated by visible progress. Show:

- **Progress bar** toward next level
- **Points earned** this session
- **Streak** (consecutive days/sessions)
- **Unlock preview** ("50 more points to unlock pattern detection")

Use micro-animations for dopamine hits when earning points.

---

## What's Next

### Immediate (This Sprint)
- [ ] Implement `BehavioralProfile` in Rounds
- [ ] Add session timing/duration tracking
- [ ] Create `GapAnalyzer` for Rounds
- [ ] Design contribution UI mockups

### Near-Term (Next Month)
- [ ] Launch Rounds V2 with contribution system
- [ ] Validate gamification with real users
- [ ] Refine gap prioritization algorithm
- [ ] Build shared framework library

### Future (Backlog)
- [ ] Extract framework into reusable Swift package
- [ ] Second app (TBD â€” not golf, something with crisp utility)
- [ ] Apple Watch companion app
- [ ] Cloud sync for cross-device

---

## Closing Thought

> "The profile is NEVER complete. It deepens over weeks and months."

This is the soul of Loud Labs. We're not building tools people use. We're building relationships people have.

Every line of code should serve that vision.

---

**For Don. For every caregiver. For everyone who deserves an AI that actually knows them.**

â€” Katie & Claude, January 2026

MORE ON THE EXISTING COMPANION FRAMEWORK: 
# LOUD LABS: Companion Framework Documentation

**Created:** January 29, 2026  
**Author:** Claude (CTO) + Katie (CEO)  
**Purpose:** Complete technical and philosophical documentation for building "Proactive Hosted AI Companion" apps

---

## Table of Contents

1. [The Vision](#the-vision)
2. [Two Core Patterns](#two-core-patterns)
3. [The Five Pillars](#the-five-pillars)
4. [Technical Architecture](#technical-architecture)
5. [Rounds: Reference Implementation](#rounds-reference-implementation)
6. [The App Portfolio](#the-app-portfolio)
7. [Design Philosophy](#design-philosophy)
8. [Implementation Guidelines](#implementation-guidelines)
9. [Next Steps: Elder Bridge](#next-steps-elder-bridge)

---

## The Vision

### What We're Building

Loud Labs builds **relationships in software form**. Not tools. Not chatbots. *Companions*.

The paradigm shift: every AI product today is a **tool you operate**. User has intent â†’ user operates tool â†’ tool returns result. Even ChatGPT, even Siri. The human drives.

We're building **AI companions**. They have agency. They know you. They reach out. They remember. They grow with you. **The AI drives, and the human trusts.**

### The Core Insight

> "This is what humans actually do â€” not what they say they want."

Humans:
- Forget why they walked into a room
- Avoid hard conversations for weeks
- Lose relationships to drift, not drama
- Miss the right moment to say something
- Carry invisible emotional weight alone
- Don't know what questions to ask the expert
- Transition badly between contexts

These are the spaces where a companion can matter.

### Target Users

Non-tech Americans. Boomers. Gen-X. People with iPhones, AirPods, Apple Watches who have **never used AI before**. This will be their first experience with AI, and it should feel like texting a friend â€” not operating a computer.

---

## Two Core Patterns

### Pattern 1: COMPANION

A single-user AI relationship. The AI knows you, remembers you, reaches out to you.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPANION                   â”‚
â”‚                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚   AI    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  USER   â”‚      â”‚
â”‚   â”‚         â”‚  Trust  â”‚         â”‚      â”‚
â”‚   â”‚ Memory  â”‚  Care   â”‚  Life   â”‚      â”‚
â”‚   â”‚ Context â”‚  Growth â”‚ Context â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Examples:** Grief Companion, Sobriety Companion, First-Gen Navigator

### Pattern 2: BRIDGE

A two-sided AI relationship. The AI has a relationship with BOTH parties. It serves both. It translates between them. It notices things neither could see alone.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BRIDGE                               â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚ PARTY A â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   AI    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ PARTY B â”‚      â”‚
â”‚   â”‚         â”‚         â”‚         â”‚         â”‚         â”‚      â”‚
â”‚   â”‚ Senior  â”‚  Care   â”‚ Memory  â”‚  Care   â”‚ Family  â”‚      â”‚
â”‚   â”‚ Parent  â”‚  Trust  â”‚ Pattern â”‚  Trust  â”‚ Member  â”‚      â”‚
â”‚   â”‚         â”‚         â”‚ Notice  â”‚         â”‚         â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Critical distinction from surveillance:**

| Surveillance | Bridge |
|--------------|--------|
| One party watches another | Both parties are seen and served |
| Information flows one direction | Information flows both directions (curated) |
| Subject loses agency | Both maintain agency |
| Trust is broken | Trust is built |
| Hidden | Transparent and consensual |

**Examples:** Elder Bridge, Co-Parent Bridge, Memory Bridge

---

## The Five Pillars

Every Loud Labs app implements these five pillars:

### 1. Chat-First UI
iMessage-style bubbles. Familiar to anyone who texts. No learning curve. No forms. No settings screens. Just conversation.

### 2. Proactive AI
AI initiates every conversation. "Hi Katie! Ready to record today's rounds?" â€” not a blinking cursor waiting for input. The AI is the host. The user is the guest.

### 3. Guided Flows
Typeahead-style interaction. AI asks one question at a time. User responds. AI guides to next step. No blank canvases. No overwhelming options.

### 4. Persistent Memory
AI remembers everything â€” names, history, context. Day after day. Session after session. Feels like texting a friend who knows your situation, not a stranger you have to re-explain everything to.

### 5. Vertical Focus
Each app has ONE job. Deep, not wide. Rounds = medical translator for caregivers. Elder Bridge = daily companion for seniors with family connection. Clear, specific, expert.

---

## Technical Architecture

### Framework Layer (Shared)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPANION FRAMEWORK                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Narrative  â”‚  â”‚ Conversationâ”‚  â”‚  Presence   â”‚         â”‚
â”‚  â”‚   Memory    â”‚  â”‚    State    â”‚  â”‚   Engine    â”‚         â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚         â”‚
â”‚  â”‚ - Identity  â”‚  â”‚ - Open loopsâ”‚  â”‚ - Geo fence â”‚         â”‚
â”‚  â”‚ - Story     â”‚  â”‚ - Last topicâ”‚  â”‚ - Time      â”‚         â”‚
â”‚  â”‚ - Patterns  â”‚  â”‚ - Next move â”‚  â”‚ - Silence   â”‚         â”‚
â”‚  â”‚ - Growth    â”‚  â”‚ - Emotional â”‚  â”‚ - Context   â”‚         â”‚
â”‚  â”‚             â”‚  â”‚   read      â”‚  â”‚   triggers  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚              VOICE + CHAT LAYER                  â”‚       â”‚
â”‚  â”‚                                                  â”‚       â”‚
â”‚  â”‚  Audio-primary with text as verification layer  â”‚       â”‚
â”‚  â”‚  iMessage-style bubbles for history/review      â”‚       â”‚
â”‚  â”‚  Minimal controls, maximum conversation         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    VERTICAL PLUGINS                         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ROUNDS  â”‚  â”‚  ELDER   â”‚  â”‚UNCOUPLINGâ”‚  â”‚  (next)  â”‚   â”‚
â”‚  â”‚ Medical  â”‚  â”‚  BRIDGE  â”‚  â”‚ Divorce  â”‚  â”‚          â”‚   â”‚
â”‚  â”‚ Caregiverâ”‚  â”‚  Seniors â”‚  â”‚ Journey  â”‚  â”‚          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Architecture

**Current (Rounds implementation):** Structured + Growing

```swift
struct AIMemoryContext {
    // Core Identity (set once)
    var caregiverName: String
    var patientName: String
    var relationship: String
    var diagnosis: String
    
    // Learned Knowledge (grows over time)
    var keyMedicalFacts: [String]
    var vitalTrends: [String: [VitalReading]]
    var observedPatterns: [String]
    var ongoingConcerns: [String]
    
    // Session History
    var sessions: [SessionMemory]
    
    // Preferences (learned)
    var caregiverConcerns: [String]
    var frequentQuestions: [String]
}
```

**Future (Narrative Memory):** The AI maintains a living narrative about you, not just facts.

```
"Katie is a caregiver for her father Don, who had a double lung 
transplant at UF Gainesville. She's been through the worst of it 
and came out the other side. She started using Rounds in January 
2026. She's sharp, moves fast, doesn't like hand-holding but 
appreciates warmth. She texts more than she talks."
```

### Conversation State

Track not just what was said, but what we're in the middle of:

```swift
struct ConversationState {
    var currentThread: String        // "checking in after Tuesday's rounds"
    var openLoops: [String]          // ["waiting on biopsy results", "ask about PT"]
    var emotionalRead: String        // "anxious but holding steady"
    var nextNaturalMove: String      // "ask how Dr. Chen conversation went"
}
```

### Presence Engine (Geospatial + Temporal)

The flow for Apple Watch + AirPods + iPhone:

1. **Trigger**: User crosses geofence, time-based event, or silence trigger
2. **Haptic**: Custom pattern on Apple Watch (not a notification â€” a tap)
3. **Permission**: User taps watch or says "yeah?"
4. **Voice**: AI speaks through AirPods, explains why it reached out
5. **Action**: User responds by voice or ignores
6. **Memory**: Interaction logged, context updated

Different haptic patterns for different meanings:
- The "I noticed something" tap
- The "Don't forget" tap
- The "I'm here if you need me" tap
- The "This is important" tap

---

## Rounds: Reference Implementation

### Stack
- **Platform:** iOS 17+ (iPhone only)
- **Language:** Swift 5.9, SwiftUI
- **Speech-to-Text:** Apple Speech Framework
- **AI:** OpenAI GPT-4o-mini (~$0.002/session)
- **Storage:** Local (UserDefaults/JSON), no backend

### File Structure

```
Rounds/
â”œâ”€â”€ RoundsApp.swift              # App entry point
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ UserProfile.swift        # Caregiver identity
â”‚   â”œâ”€â”€ AIMemoryContext.swift    # Persistent AI memory (THE KEY FILE)
â”‚   â”œâ”€â”€ RecordingSession.swift   # Single recording session
â”‚   â””â”€â”€ RoundsAnalysis.swift     # AI analysis results
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ STTService.swift         # Speech-to-text (Apple Speech)
â”‚   â”œâ”€â”€ OpenAIService.swift      # GPT integration + learning loop
â”‚   â”œâ”€â”€ ProfileStore.swift       # User persistence
â”‚   â””â”€â”€ SessionStore.swift       # Session persistence
â”œâ”€â”€ ViewModels/
â”‚   â””â”€â”€ TranscriptViewModel.swift # Core state management
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ RootView.swift           # Navigation controller
â”‚   â”œâ”€â”€ Onboarding/
â”‚   â”‚   â””â”€â”€ OnboardingFlow.swift # 5-step setup as conversation
â”‚   â”œâ”€â”€ LandingView.swift        # Main recording interface
â”‚   â”œâ”€â”€ PreviousRoundsView.swift # Session history
â”‚   â””â”€â”€ SplashView.swift         # Launch screen
â””â”€â”€ Resources/
    â”œâ”€â”€ Colors.swift             # Design system
    â”œâ”€â”€ Config.plist             # API keys
    â””â”€â”€ Assets.xcassets          # Images
```

### Key Implementation Details

**1. Memory Learning Loop** (OpenAIService.swift)

The AI learns from each session and stores new facts:

```swift
struct ExtendedAnalysis: Codable {
    let explanation: String
    let summaryPoints: [String]
    let followUpQuestions: [String]
    let newFactsLearned: [String]?     // â† Stored for future
    let vitalValues: [String: Double]? // â† Tracked over time
    let concerns: [String]?
    let patterns: [String]?            // â† Observed across sessions
}
```

**2. System Prompt with Full Context** (AIMemoryContext.swift)

Every API call includes the full patient context:

```swift
func buildSystemContext() -> String {
    var context = """
    You are Rounds AI, \(caregiverName)'s dedicated medical assistant.
    You've been helping \(caregiverName) care for their \(relationship) \(patientName).
    
    PATIENT INFORMATION:
    - Name: \(patientName)
    - Diagnosis: \(diagnosis)
    - Day \(daysSinceSurgery ?? 0) post-surgery
    
    MEDICAL FACTS YOU'VE LEARNED:
    \(keyMedicalFacts.map { "- \($0)" }.joined(separator: "\n"))
    
    PATTERNS YOU'VE NOTICED:
    \(observedPatterns.map { "- \($0)" }.joined(separator: "\n"))
    
    PAST SESSION SUMMARIES:
    \(sessions.suffix(7).map { formatSession($0) }.joined(separator: "\n"))
    """
    return context
}
```

**3. Session Chaining** (TranscriptViewModel.swift)

Multiple recordings within 1 hour are treated as one session:

```swift
private func shouldChainToExistingSession(currentTime: Date) -> Bool {
    guard let startTime = sessionStartTime else { return false }
    let elapsed = currentTime.timeIntervalSince(startTime)
    let hasExistingContent = !liveTranscript.isEmpty || analysis != nil
    return elapsed < sessionChainWindowSeconds && hasExistingContent
}
```

**4. Onboarding as Guided Conversation** (OnboardingFlow.swift)

5 steps, each feels like a message in a chat:
1. Welcome ("Hi. I'm Rounds AI.")
2. Your name
3. Patient name + relationship
4. Situation description
5. Permissions (mic + speech)

---

## The App Portfolio

### TIER 1 â€” Ready to Build

| App | Pattern | One-Line |
|-----|---------|----------|
| **Rounds** | Companion | Medical translator for caregivers during hospital stays |
| **Elder Bridge** | Bridge | Daily companion for seniors that connects family with peace of mind |
| **Uncoupling** | Companion â†’ Bridge | Navigate separation from first doubt through rebuilding |

### TIER 2 â€” Strong Concepts

| App | Pattern | One-Line |
|-----|---------|----------|
| **Memory Bridge** | Bridge | Preserve a person's stories while they can still tell them |
| **Chronic Care Companion** | Companion + Bridge | Daily life support for long-term caregiving |
| **Grief Companion** | Companion | A witness for the first year (and beyond) |
| **Sobriety Companion** | Companion â†’ Bridge | Recovery support with optional accountability |
| **First-Gen Navigator** | Companion | The advisor first-gen students never had |
| **Co-Parent Bridge** | Bridge | Reduce conflict, coordinate logistics, protect kids |

### TIER 3 â€” Functional (Not Just Emotional)

| App | Pattern | One-Line |
|-----|---------|----------|
| **Estate Companion** | Companion | Navigate probate and executor duties step by step |
| **Immigration Companion** | Companion | Track cases, prep for interviews, adjust to new life |
| **First Home Companion** | Companion | Guide through the most complex transaction of their life |
| **Small Business Companion** | Companion | The advisor you can't afford |

---

## Design Philosophy

### Jony Ives Principles

1. **Guided, not open-ended.** We take users by the hand. Every interaction feels like a typeahead form, not a blank canvas.

2. **Stupid-simple, but elegant.** Like the Jitterbug phone â€” big buttons, clear labels, no learning curve. But it should still feel like an Apple product.

3. **Fast.** No spinners. No waiting. Real-time streaming. AI responds in seconds.

4. **Warm.** The AI has a personality: calm, competent, never condescending. Like a friend who happens to be an expert.

5. **Trustworthy.** We never forget. We never give advice we're not qualified to give. We're honest about limitations.

### Trust-Building Disclosure

Capabilities emerge *relationally*, not all at once:

- **Week 1:** "I'm here to help you remember what the doctors say."
- **Week 3:** "I've noticed you always ask about medications â€” want me to keep a running list?"
- **Week 6:** "You've been doing this for a while. Want me to summarize the whole journey for your sister?"

### Voice as Primary

For older users especially: the most natural interface is talking.

The screen becomes minimal:
- A waveform showing it's listening
- Transcription scrolling as text (for verification)
- One tap to pause, one tap to end

The AI responds by voice too. Text is the *receipt*, not the interface.

---

## Implementation Guidelines

### Rules for the Engineering Claude

1. **Never invent architecture.** Execute the spec. Ask clarifying questions first.
2. **Write production-grade Swift.** Clean, modular, compiles without hypotheticals.
3. **iOS 17+ only.** Swift 5.9+. SwiftUI. No legacy support.
4. **All data local.** No backend unless explicitly architected.
5. **Memory is sacred.** The learning loop must work. AI must remember.
6. **Respect the Rounds codebase.** Don't rewrite working components.

### File Locations

- **Rounds project:** `/Users/katiemacair-2025/04_Developer/Rounds/`
- **This doc:** `/Users/katiemacair-2025/04_Developer/LOUD_LABS_COMPANION_FRAMEWORK.md`
- **New projects:** `/Users/katiemacair-2025/04_Developer/{AppName}/`

### Key Files to Study

Before building any new app, read these Rounds files:
1. `AIMemoryContext.swift` â€” The memory architecture
2. `OpenAIService.swift` â€” The learning loop implementation
3. `OnboardingFlow.swift` â€” Guided conversation onboarding
4. `TranscriptViewModel.swift` â€” Session state management

---

## Next Steps: Elder Bridge

### The Concept

**Elder Bridge** is the first **Bridge pattern** app.

**Party A (Senior):** Gets a daily AI companion. Someone to talk to. Someone who listens. Someone who notices and remembers.

**Party B (Family):** Gets peace of mind. Subtle flags if something seems off. Connection without surveillance. The ability to know "Mom's doing okay" without having to call every day.

**The AI:** Holds relationship with both. Serves both. Translates between them. Notices patterns neither could see alone.

### Key Differentiators from Rounds

| Rounds | Elder Bridge |
|--------|--------------|
| Single user (caregiver) | Two users (senior + family) |
| Recording-centric | Conversation-centric |
| Episodic (around appointments) | Daily (ongoing relationship) |
| Functional output (summaries) | Relational output (connection) |
| Memory serves task | Memory serves person |

### Technical Considerations

1. **Two user models** â€” Senior profile + Family profile, linked
2. **Permission architecture** â€” What can family see? Senior controls.
3. **Pattern detection** â€” Speech patterns, mood, coherence, topics
4. **Gentle alerts** â€” Not alarms. "You might want to call Mom this week."
5. **Story preservation** â€” Capturing memories while they can still be told

### First Sprint Questions

1. Does the senior know family gets updates? (Yes â€” transparent)
2. What does the daily interaction look like? (Voice? Chat? Both?)
3. What patterns are we detecting? (Mood? Confusion? Isolation?)
4. How does family receive updates? (Push? Digest? On-demand?)
5. What's the onboarding for BOTH parties?

---

## Appendix: Brand Colors (Rounds)

```swift
struct RoundsColor {
    static let buttonBlue = Color(red: 56/255, green: 152/255, blue: 224/255)
    static let moduleBackground = buttonBlue.opacity(0.08)
    static let textDark = Color(red: 40/255, green: 40/255, blue: 50/255)
    static let textMedium = Color(red: 80/255, green: 80/255, blue: 90/255)
    static let textMuted = Color.gray
}
```

---

*This document is the handoff for any Claude instance continuing Loud Labs work. Read it fully before beginning implementation.*

**For Don. For every caregiver. For every person who deserves a companion.**

â€” Katie & Claude, January 2026

